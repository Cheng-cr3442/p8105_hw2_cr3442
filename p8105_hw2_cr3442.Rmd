---
title: "p8105_hw2_cr3442"
author: "Cheng Rao"
date: "2024-10-02"
output: github_document
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning = FALSE,message = FALSE,tidy = TRUE)
```

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

First, let us read and clean the NYC Transit data.

```{r nyc_data}
#Read and clean the NYC Transit data
nyc_trans_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  ) %>%
  janitor::clean_names() %>% 
  
#Retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance
  select(
    .,line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada
    )  %>%
  
#Convert the entry variable from character to a logical variable
  mutate(
    entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
    vending = recode(vending, "YES" = TRUE, "NO" = FALSE),
      )
  
#check if the variables are right or not
str(nyc_trans_df)
```

In the above process, we loaded the NYC Transit dataset and named it `nyc_trans_df`. There are `r nrow(nyc_trans_df)` rows and `r ncol(nyc_trans_df)` columns in the dataset `nyc_trans_df`. And we cleaned the names of columns, selected the desired variables and changed two character variables to logical variables ---- `entry` and `vending`. The dataset contained the following variables: `r colnames( nyc_trans_df)`. These data are not tidy enough.

Then we are going to answer the questions of Problem 1.

```{r using_these_data, include = FALSE}
#Use distinct() based on line and station_name to find number of stations
station_distinct =
  distinct(
    nyc_trans_df, line, station_name, .keep_all = TRUE
    )

#Filtering ADA with filter()
ada_compliant = 
  filter(
    station_distinct, ada == TRUE
  )

```


```{r using_data_prop, include = FALSE}
#Filter subway stations that without ticket vending machines but allow entry
n1 = 
  filter(
    nyc_trans_df, vending == FALSE & entry == TRUE
  ) %>% 
  nrow()

#Filter subway stations without ticket vending machines
n2 = 
  filter(
    nyc_trans_df, vending == FALSE
  ) %>% 
  nrow()

```

At last reformat the data.

```{r reformat_data}
#Reformat
dist_route_df = station_distinct %>%
#Convert
mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route",
    values_to = "train")

#Output the front part of the reformatted data frame
head(dist_route_df)
```


* **Answers:**
- 1.There are `r nrow(station_distinct)` stations in NYC.
- 2.There are `r nrow(ada_compliant)` ADA compliant.
- 3.The proportion of station entrances / exits without vending allow entrance is `r n1/n2`.
- 4.There are `r nrow(filter(dist_route_df, train == "A"))` stations serving the A train.
- 5.The number of distinct stations serving the A train and are ADA compliant is `r nrow(filter(dist_route_df, train == "A" & ada == "TRUE"))`.

  
# Problem 2

First, 

Read and clean the `Mr. Trash Wheel` dataset.

```{r trash_data}
mr_trash_path = "./data/202309 Trash Wheel Collection Data.xlsx"
mr_trash = 
  read_excel(
    path = mr_trash_path,
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")
  ) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    trash_wheel = "Mr. Trash Wheel"
  )

```

Read and clean the `Professor Trash Wheel` dataset.

```{r prof_trash_data}
prof_trash = 
  read_excel(
    path = mr_trash_path,
    sheet = "Professor Trash Wheel",
    range = cell_cols("A:N")
  ) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    trash_wheel = "Professor Trash Wheel"
  )

```

Read and clean the `Gwynnda` dataset.

```{r gwynnda_trash_data}
gwynnda_trash = 
  read_excel(
    path = mr_trash_path,
    sheet = "Gwynnda Trash Wheel",
    range = cell_cols("A:N")
  ) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    trash_wheel = "Gwynnda"
  )

```

Get the common columns of these datasets and check missing data.
```{r prepare for merge}
#Get common and unique columns of all dataframes
required_columns <- c("dumpster", "month", "year", "date", "weight_tons", "volume_cubic_yards", 
                      "plastic_bottles", "polystyrene", "cigarette_butts", "glass_bottles", 
                      "plastic_bags", "wrappers", "homes_powered", "trash_wheel")

#Check and add missing columns
add_missing_columns <- function(df, required_columns) {
  missing_cols <- setdiff(required_columns, names(df))
#Add NA for missing data
  df[missing_cols] <- NA  
  return(df)
}

mr_trash <- add_missing_columns(mr_trash, required_columns)
prof_trash <- add_missing_columns(prof_trash, required_columns)
gwynnda_trash <- add_missing_columns(gwynnda_trash, required_columns)

```

```{r conversion}
#Conversion of column types
mr_trash <- mr_trash %>%
  mutate(
    month = as.character(month),
    year = as.character(year),
    date = as.Date(date),
    weight_tons = as.numeric(weight_tons),
    volume_cubic_yards = as.numeric(volume_cubic_yards),
    plastic_bottles = as.numeric(plastic_bottles),
    polystyrene = as.numeric(polystyrene),
    cigarette_butts = as.numeric(cigarette_butts),
    glass_bottles = as.numeric(glass_bottles),
    plastic_bags = as.numeric(plastic_bags),
    wrappers = as.numeric(wrappers),
    homes_powered = as.numeric(homes_powered)
  )

prof_trash <- prof_trash %>%
  mutate(
    month = as.character(month),
    year = as.character(year),
    date = as.Date(date),
    weight_tons = as.numeric(weight_tons),
    volume_cubic_yards = as.numeric(volume_cubic_yards),
    plastic_bottles = as.numeric(plastic_bottles),
    polystyrene = as.numeric(polystyrene),
    cigarette_butts = as.numeric(cigarette_butts),
    glass_bottles = as.numeric(glass_bottles),
    plastic_bags = as.numeric(plastic_bags),
    wrappers = as.numeric(wrappers),
    homes_powered = as.numeric(homes_powered)
  )

gwynnda_trash <- gwynnda_trash %>%
  mutate(
    month = as.character(month),
    year = as.character(year),
    date = as.Date(date),
    weight_tons = as.numeric(weight_tons),
    volume_cubic_yards = as.numeric(volume_cubic_yards),
    plastic_bottles = as.numeric(plastic_bottles),
    polystyrene = as.numeric(polystyrene),
    cigarette_butts = as.numeric(cigarette_butts),
    glass_bottles = as.numeric(glass_bottles),
    plastic_bags = as.numeric(plastic_bags),
    wrappers = as.numeric(wrappers),
    homes_powered = as.numeric(homes_powered)
  )

```

Finally we can merge the three datasets.
```{r merge}
trash_df <- bind_rows(mr_trash, prof_trash, gwynnda_trash)

str(trash_df)

```

And it works!

Now we can observe and describe the merged data frame.

```{r describe}
total_observations <- nrow(trash_df)

variable_names <- names(trash_df)

```

And we can calculate the sprots balls of Mr Trash Wheel.

```{r balls}
mr_trash_balls <- trash_df %>%
  filter(trash_wheel == "Mr. Trash Wheel") %>%
  summarize(total_balls = as.integer(round(sum(sports_balls, na.rm = TRUE)))) %>%
  pull(total_balls)

```

And we can calculate the total weight of trash collected by Professor Trash Wheel and the total number of cigarette butts collected by Gwynnda in June of 2022.

```{r calculating}

total_weight_professor <- trash_df %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  summarize(total_weight = sum(weight_tons, na.rm = TRUE)) %>%
  pull(total_weight)

gwynnda_cig_butts_june_2022 <- trash_df %>%
  filter(trash_wheel == "Gwynnda", year == "2022", month == "June") %>%
  summarize(total_cig_butts = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total_cig_butts)

```

* **Answers:**
- 1.Mr. Trash Wheel has collected a total of `r mr_trash_balls` basketballs.
- 2.The variables of the merged data frame include: `r variable_names`, for example, `weight_tons` represents the weight of each garbage collection, `plastic_bottles` represents the number of plastic bottles collected, and `cigarette_butts` represents the number of cigarette butts collected.
- 3.The total weight of trash collected by `Professor Trash Wheel` is `r total_weight_professor` tons.
- 4.The total number of cigarette butts collected by `Gwynnda` in June 2022 was `r gwynnda_cig_butts_june_2022`.